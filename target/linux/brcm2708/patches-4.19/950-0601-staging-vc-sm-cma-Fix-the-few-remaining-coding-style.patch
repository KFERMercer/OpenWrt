From 38ae4957840ff9578a497422a8ca758549f734d5 Mon Sep 17 00:00:00 2001
From: Dave Stevenson <dave.stevenson@raspberrypi.org>
Date: Tue, 2 Jul 2019 17:19:04 +0100
Subject: [PATCH] staging: vc-sm-cma: Fix the few remaining coding
 style issues

Fix a few minor checkpatch complaints to make the driver clean

Signed-off-by: Dave Stevenson <dave.stevenson@raspberrypi.org>
---
 .../staging/vc04_services/vc-sm-cma/vc_sm.c   |   6 +-
 .../vc04_services/vc-sm-cma/vc_sm_cma_vchi.c  | 128 +++++++++---------
 2 files changed, 65 insertions(+), 69 deletions(-)

--- a/drivers/staging/vc04_services/vc-sm-cma/vc_sm.c
+++ b/drivers/staging/vc04_services/vc-sm-cma/vc_sm.c
@@ -325,7 +325,6 @@ static void vc_sm_release_resource(struc
 				  buffer->cookie, buffer->dma_addr);
 	}
 
-
 	/* Free our buffer. Start by removing it from the list */
 	mutex_lock(&sm_state->map_lock);
 	list_del(&buffer->global_buffer_list);
@@ -1365,7 +1364,8 @@ static int vc_sm_cma_clean_invalid2(unsi
 	}
 
 	for (i = 0; i < ioparam.op_count; i++) {
-		const struct vc_sm_cma_ioctl_clean_invalid_block * const op = block + i;
+		const struct vc_sm_cma_ioctl_clean_invalid_block * const op =
+								block + i;
 
 		if (op->invalidate_mode == VC_SM_CACHE_OP_NOP)
 			continue;
@@ -1637,8 +1637,6 @@ err_remove_misc_dev:
 err_remove_debugfs:
 	debugfs_remove_recursive(sm_state->dir_root);
 	vc_sm_cma_vchi_stop(&sm_state->sm_handle);
-
-	return;
 }
 
 /* Driver loading. */
--- a/drivers/staging/vc04_services/vc-sm-cma/vc_sm_cma_vchi.c
+++ b/drivers/staging/vc04_services/vc-sm-cma/vc_sm_cma_vchi.c
@@ -188,79 +188,77 @@ static int vc_sm_cma_vchi_videocore_io(v
 		if (svc_use)
 			vchi_service_release(instance->vchi_handle[0]);
 		svc_use = 0;
-		if (!wait_for_completion_interruptible(&instance->io_cmplt)) {
-			vchi_service_use(instance->vchi_handle[0]);
-			svc_use = 1;
-
-			do {
-				/*
-				 * Get new command and move it to response list
-				 */
-				mutex_lock(&instance->lock);
-				if (list_empty(&instance->cmd_list)) {
-					/* no more commands to process */
-					mutex_unlock(&instance->lock);
-					break;
-				}
-				cmd =
-				    list_first_entry(&instance->cmd_list,
-						     struct sm_cmd_rsp_blk,
-						     head);
-				list_move(&cmd->head, &instance->rsp_list);
-				cmd->sent = 1;
-				mutex_unlock(&instance->lock);
 
-				/* Send the command */
-				status = bcm2835_vchi_msg_queue(
-						instance->vchi_handle[0],
-						cmd->msg, cmd->length);
-				if (status) {
-					pr_err("%s: failed to queue message (%d)",
-					       __func__, status);
-				}
-
-				/* If no reply is needed then we're done */
-				if (!cmd->wait) {
-					mutex_lock(&instance->lock);
-					list_del(&cmd->head);
-					mutex_unlock(&instance->lock);
-					vc_vchi_cmd_delete(instance, cmd);
-					continue;
-				}
-
-				if (status) {
-					complete(&cmd->cmplt);
-					continue;
-				}
-
-			} while (1);
-
-			while (!vchi_msg_peek(instance->vchi_handle[0],
-					      (void **)&reply, &reply_len,
-					      VCHI_FLAGS_NONE)) {
-				if (reply->trans_id & 0x80000000) {
-					/* Async event or cmd from the VPU */
-					if (instance->vpu_event)
-						instance->vpu_event(
-							instance, reply,
-							reply_len);
-				} else {
-					vc_sm_cma_vchi_rx_ack(instance, cmd,
-							      reply, reply_len);
-				}
+		if (wait_for_completion_interruptible(&instance->io_cmplt))
+			continue;
 
-				vchi_msg_remove(instance->vchi_handle[0]);
-			}
+		vchi_service_use(instance->vchi_handle[0]);
+		svc_use = 1;
 
-			/* Go through the dead list and free them */
+		do {
+			/*
+			 * Get new command and move it to response list
+			 */
 			mutex_lock(&instance->lock);
-			list_for_each_entry_safe(cmd, cmd_tmp,
-						 &instance->dead_list, head) {
+			if (list_empty(&instance->cmd_list)) {
+				/* no more commands to process */
+				mutex_unlock(&instance->lock);
+				break;
+			}
+			cmd = list_first_entry(&instance->cmd_list,
+					       struct sm_cmd_rsp_blk, head);
+			list_move(&cmd->head, &instance->rsp_list);
+			cmd->sent = 1;
+			mutex_unlock(&instance->lock);
+
+			/* Send the command */
+			status =
+				bcm2835_vchi_msg_queue(instance->vchi_handle[0],
+						       cmd->msg, cmd->length);
+			if (status) {
+				pr_err("%s: failed to queue message (%d)",
+				       __func__, status);
+			}
+
+			/* If no reply is needed then we're done */
+			if (!cmd->wait) {
+				mutex_lock(&instance->lock);
 				list_del(&cmd->head);
+				mutex_unlock(&instance->lock);
 				vc_vchi_cmd_delete(instance, cmd);
+				continue;
 			}
-			mutex_unlock(&instance->lock);
+
+			if (status) {
+				complete(&cmd->cmplt);
+				continue;
+			}
+
+		} while (1);
+
+		while (!vchi_msg_peek(instance->vchi_handle[0], (void **)&reply,
+				      &reply_len, VCHI_FLAGS_NONE)) {
+			if (reply->trans_id & 0x80000000) {
+				/* Async event or cmd from the VPU */
+				if (instance->vpu_event)
+					instance->vpu_event(instance, reply,
+							    reply_len);
+			} else {
+				vc_sm_cma_vchi_rx_ack(instance, cmd, reply,
+						      reply_len);
+			}
+
+			vchi_msg_remove(instance->vchi_handle[0]);
+		}
+
+		/* Go through the dead list and free them */
+		mutex_lock(&instance->lock);
+		list_for_each_entry_safe(cmd, cmd_tmp, &instance->dead_list,
+					 head) {
+			list_del(&cmd->head);
+			vc_vchi_cmd_delete(instance, cmd);
 		}
+		mutex_unlock(&instance->lock);
 	}
 
 	return 0;
